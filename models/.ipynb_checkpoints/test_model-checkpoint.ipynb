{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "# Define a resnet block\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim),\n",
    "                       activation]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "def get_grid(batchsize, rows, cols, gpu_id=0, dtype=torch.float32):\n",
    "    hor = torch.linspace(-1.0, 1.0, cols)\n",
    "    hor.requires_grad = False\n",
    "    hor = hor.view(1, 1, 1, cols)\n",
    "    hor = hor.expand(batchsize, 1, rows, cols)\n",
    "    ver = torch.linspace(-1.0, 1.0, rows)\n",
    "    ver.requires_grad = False\n",
    "    ver = ver.view(1, 1, rows, 1)\n",
    "    ver = ver.expand(batchsize, 1, rows, cols)\n",
    "\n",
    "    t_grid = torch.cat([hor, ver], 1)\n",
    "    t_grid.requires_grad = False\n",
    "\n",
    "    if dtype == torch.float16: t_grid = t_grid.half()\n",
    "    return t_grid.cuda(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([4, 9, 256, 192])\n",
      "torch.Size([4, 3, 256, 192])\n",
      "torch.Size([4, 512, 32, 24])\n",
      "torch.Size([4, 512, 32, 24])\n",
      "flow\n",
      "warp\n",
      "torch.Size([4, 3, 256, 192])\n"
     ]
    }
   ],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNetwork, self).__init__()\n",
    "\n",
    "    def grid_sample(self, input1, input2):\n",
    "        if self.opt.fp16: # not sure if it's necessary\n",
    "            return torch.nn.functional.grid_sample(input1.float(), input2.float(), mode='bilinear', padding_mode='border').half()\n",
    "        else:\n",
    "            return torch.nn.functional.grid_sample(input1, input2, mode='bilinear', padding_mode='border')\n",
    "\n",
    "    #计算光流warp\n",
    "    def resample(self, image, flow, normalize=True):        \n",
    "        b, c, h, w = image.size()        \n",
    "        if not hasattr(self, 'grid') or self.grid.size() != flow.size():\n",
    "            self.grid = get_grid(b, h, w, gpu_id=flow.get_device(), dtype=flow.dtype)            \n",
    "        if normalize:\n",
    "            flow = torch.cat([flow[:, 0:1, :, :] / ((w - 1.0) / 2.0), flow[:, 1:2, :, :] / ((h - 1.0) / 2.0)], dim=1)        \n",
    "        final_grid = (self.grid + flow).permute(0, 2, 3, 1).cuda(image.get_device())\n",
    "        output = self.grid_sample(image, final_grid)\n",
    "        return output\n",
    "\n",
    "class Part_Cloth(BaseNetwork):\n",
    "    def __init__(self, opt, input_nc_1, input_nc_2, output_nc, ngf, n_downsampling, n_blocks, use_fg_model=False, no_flow=False,\n",
    "                norm_layer=nn.BatchNorm2d, padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(Part_Cloth, self).__init__()                \n",
    "        self.opt = opt\n",
    "        self.n_downsampling = n_downsampling\n",
    "        self.use_fg_model = use_fg_model\n",
    "        self.no_flow = no_flow\n",
    "        activation = nn.ReLU(True)\n",
    "        \n",
    "        ### flow and image generation\n",
    "        ### downsample,对这三个输入分别进行下采样        \n",
    "        model_down_1 = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc_1, ngf, kernel_size=7, padding=0), norm_layer(ngf), activation]\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model_down_1 += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                               norm_layer(ngf * mult * 2), activation]  \n",
    "\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks - n_blocks//2):\n",
    "            model_down_1 += [ResnetBlock(ngf * mult, padding_type=padding_type, activation=activation, norm_layer=norm_layer)]\n",
    "        \n",
    "        model_down_2 = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc_2, ngf, kernel_size=7, padding=0), norm_layer(ngf), activation]\n",
    "        model_down_2 += copy.deepcopy(model_down_1[4:])\n",
    "        \n",
    "        #只输入两部分好了\n",
    "#         model_down_lo = [nn.ReflectionPad2d(3), nn.Conv2d(prev_output_nc, ngf, kernel_size=7, padding=0), norm_layer(ngf), activation]\n",
    "#         model_down_lo += copy.deepcopy(model_down_T[4:])\n",
    "    \n",
    "    \n",
    "    \n",
    "        ### resnet blocks \n",
    "        model_res_part = []\n",
    "        for i in range(n_blocks//2):\n",
    "            model_res_part += [ResnetBlock(ngf * mult, padding_type=padding_type, activation=activation, norm_layer=norm_layer)]\n",
    "\n",
    "        ### upsample\n",
    "        model_up_part = []\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model_up_part += [nn.ConvTranspose2d(ngf*mult, ngf*mult//2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                             norm_layer(ngf*mult//2), activation]  \n",
    "            \n",
    "        ### 最后再用卷积处理一下生成12个通道，最后再使用softmax处理生成粗糙的结果\n",
    "        model_final_part = [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model_final_softmax = [nn.Softmax(dim=1)]\n",
    "        #model_final_logsoftmax = [nn.LogSoftmax(dim=1)]\n",
    "\n",
    "        \n",
    "        #计算这三帧的flow\n",
    "        model_res_flow = copy.deepcopy(model_res_part)\n",
    "        model_up_flow = copy.deepcopy(model_up_part)\n",
    "        model_final_flow = [nn.ReflectionPad2d(3), nn.Conv2d(ngf, 2, kernel_size=7, padding=0)]                \n",
    "        model_final_w = [nn.ReflectionPad2d(3), nn.Conv2d(ngf, 1, kernel_size=7, padding=0), nn.Sigmoid()] \n",
    "\n",
    "        #将网络连接在一起\n",
    "        self.model_down_1 = nn.Sequential(*model_down_1)        \n",
    "        self.model_down_2 = nn.Sequential(*model_down_2)        \n",
    "        #self.model_down_lo = nn.Sequential(*model_down_lo)        \n",
    "        self.model_res_part = nn.Sequential(*model_res_part)\n",
    "        self.model_up_part = nn.Sequential(*model_up_part)\n",
    "        self.model_final_part = nn.Sequential(*model_final_part)\n",
    "        self.model_final_softmax = nn.Sequential(*model_final_softmax)\n",
    "        #self.model_final_logsoftmax = nn.Sequential(*model_final_logsoftmax)\n",
    "        self.model_res_flow = nn.Sequential(*model_res_flow)\n",
    "        self.model_up_flow = nn.Sequential(*model_up_flow)\n",
    "        self.model_final_flow = nn.Sequential(*model_final_flow)\n",
    "        self.model_final_w = nn.Sequential(*model_final_w)\n",
    "    \n",
    "\n",
    "        \n",
    "    #生成局部衣服\n",
    "    def forward(self, t_part, s_parsing, t_prev,use_raw_only):\n",
    "        #print(\"input_T, input_S, lo_prev, use_raw_only\",input_T.shape, input_S.shape, lo_prev.shape, use_raw_only)\n",
    "        #torch.Size([4, 12, 256, 192]) torch.Size([4, 9, 256, 192]) torch.Size([4, 24, 256, 192])\n",
    "        gpu_id = t_part.get_device()\n",
    "        print(gpu_id)\n",
    "        t_part = torch.cat((t_prev,t_part),axis=1)\n",
    "        print(t_part.shape)\n",
    "        print(s_parsing.shape)\n",
    "        \n",
    "        #对这两个数据分别进行下采样\n",
    "        downsample_1 = self.model_down_1(s_parsing)   #3,\n",
    "        downsample_2 = self.model_down_2(t_part)      #9\n",
    "       \n",
    "        print(downsample_1.shape)\n",
    "        print(downsample_2.shape)\n",
    "        \n",
    "        #得到特征图并生成图像\n",
    "        part_feat = self.model_up_part(self.model_res_part(downsample_1+downsample_2))\n",
    "        part_raw = self.model_final_part(part_feat)\n",
    "        \n",
    "        #是否需要计算flow\n",
    "        flow = weight = flow_feat = None\n",
    "        if not self.no_flow:\n",
    "            print(\"flow\")\n",
    "            flow_feat = self.model_up_flow(self.model_res_flow(downsample_1))\n",
    "            flow = self.model_final_flow(flow_feat) * 20\n",
    "            weight = self.model_final_w(flow_feat)\n",
    "        \n",
    "        #是否需要warp\n",
    "        if use_raw_only or self.no_flow:\n",
    "            part_final = part_raw\n",
    "        else:\n",
    "            print(\"warp\")\n",
    "            part_warp = self.resample(t_prev[:,-3:,...].cuda(gpu_id), flow).cuda(gpu_id)        \n",
    "            weight_ = weight.expand_as(part_raw)\n",
    "            part_final = part_raw * weight_ + part_warp * (1-weight_)\n",
    "\n",
    "                \n",
    "        print(part_final.shape)      \n",
    "        return part_final, part_raw, flow, weight\n",
    "        #fake_slo, fake_slo_raw, fake_slo_ls, fake_slo_raw_ls, flow, weight\n",
    "        \n",
    "#这3部分如何处理呢\n",
    "t_1 = Variable(torch.rand(4,3,256,192).cuda(1))#  1\n",
    "s_1 = Variable(torch.rand(4,3,256,192).cuda(1))#0,1,2,背景，上衣，下衣 3\n",
    "t_prev = Variable(torch.rand(4,6,256,192).cuda(1))# 2\n",
    "#s_1 = Variable(torch.rand(2,3,256,196))，这是gt\n",
    "\n",
    "parser = argparse.ArgumentParser()     \n",
    "parser.add_argument('--batch', type=int, default=1, help='input batch size')\n",
    "parser.add_argument('--fp16', action='store_true', default=False, help='train with AMP')\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "#模型参数 opt, input_nc_1, input_nc_2, output_nc, prev_output_nc, ngf, n_downsampling, n_blocks,\n",
    "input_nc_1 = 3\n",
    "input_nc_2 = 9\n",
    "output_nc = 3\n",
    "ngf = 64\n",
    "n_downsampling = 3\n",
    "n_blocks = 9\n",
    "use_raw_only = False\n",
    "\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "net = Part_Cloth(opt,input_nc_1,input_nc_2,output_nc,ngf,n_downsampling,n_blocks)\n",
    "net.to(device)\n",
    "\n",
    "t_part = t_1\n",
    "s_parsing = s_1\n",
    "\n",
    "#保证输入是这三个\n",
    "output = net(t_part, s_parsing, t_prev, use_raw_only)\n",
    "\n",
    "#输入：目标局部衣服，源语义图，前两帧生成的目标局部衣服\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0, 1, 12):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(0, 12, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8]\n",
    "print(a[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6612, 0.9598, 0.9742],\n",
      "        [0.3327, 0.2073, 0.9006]])\n",
      "tensor([[0.4617, 0.8045, 0.2320],\n",
      "        [0.7412, 0.9151, 0.4362]])\n",
      "tensor([[0.6612, 0.9598, 0.9742, 0.4617, 0.8045, 0.2320],\n",
      "        [0.3327, 0.2073, 0.9006, 0.7412, 0.9151, 0.4362]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(2,3)\n",
    "print(a)\n",
    "b = torch.rand(2,3)\n",
    "print(b)\n",
    "c = torch.cat([a,b],dim=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 16, 16])\n",
      "torch.Size([1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1,12,16,16)\n",
    "b = a[0].max(0, keepdim=True)[1]#0是具体的值，1是index\n",
    "print(a[0].shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "b = a.max(0,keepdim=True)[1]\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "print(a[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk torch.Size([2, 5, 256])\n",
      "qk torch.Size([2, 5, 256])\n",
      "torch.Size([2, 256])\n",
      "m1 torch.Size([2, 256, 1])\n",
      "q1 torch.Size([2, 1, 256])\n",
      "torch.Size([2, 5, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_affinity(mk, qk):\n",
    "        B, CK, h, w = mk.shape  #2,5,16,16\n",
    "        mk = mk.flatten(start_dim=2)\n",
    "        qk = qk.flatten(start_dim=2)\n",
    "\n",
    "        print(\"mk\",mk.shape)#2,5,256\n",
    "        print(\"qk\",qk.shape)#2,5,256\n",
    "\n",
    "        #先所有元素平方，然后c通道相加\n",
    "        m1 = torch.sqrt(mk.pow(2).sum(1).unsqueeze(2))#2,5,256--->2,256---->2,256,1\n",
    "        q1 = torch.sqrt(qk.pow(2).sum(1).unsqueeze(1))#2,5,256--->2,256---->2,1,256\n",
    "        print(\"m1\",m1.shape)\n",
    "        print(\"q1\",q1.shape)\n",
    "        mq = m1@q1   #2,256,1*2,1,256 = 2,256,256\n",
    "      \n",
    "\n",
    "        #计算余弦距离\n",
    "        b = (mk.transpose(1, 2) @ qk)#2,256,5*2,5,256--->2,256,256\n",
    "        \n",
    "        affinity = b/ mq   # B, THW, HW\n",
    "        #print(\"affinity\",affinity.shape)\n",
    "\n",
    "        # softmax operation; aligned the evaluation style\n",
    "        x_exp = torch.exp(affinity)#2,256,256\n",
    "        x_exp_sum = torch.sum(x_exp, dim=1, keepdim=True)#2,256,256-->2,1,256\n",
    "   \n",
    "        affinity = x_exp / x_exp_sum \n",
    "\n",
    "        #print(affinity.sum(1))\n",
    "\n",
    "        return affinity\n",
    "\n",
    "    #mv是补充信息\n",
    "def fusion(mv,qv):\n",
    "        B, CV, H, W = qv.shape\n",
    "        affinity = get_affinity(mv,qv)\n",
    "        mo = mv.view(B, CV, H*W)#2,12,16\n",
    "        mem = torch.bmm(mo, affinity)#2,12,16*2,16,16 = 2,12,16\n",
    "        mem = mem.view(B, CV, H, W)\n",
    "        mem_out = qv+mem\n",
    "\n",
    "        return mem_out\n",
    "    \n",
    "mv = torch.randn((2,5,16,16))\n",
    "qv = torch.randn((2,5,16,16))\n",
    "out = fusion(mv,qv)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
